{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/towet/Desktop/OpenProjects/MRI-CT-Translator/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/towet/Desktop/OpenProjects/MRI-CT-Translator'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "from pathlib import Path \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir : Path \n",
    "    model_path : Path \n",
    "    dataset : Path \n",
    "    img_shape : tuple\n",
    "    epochs : int\n",
    "    lr : float\n",
    "    l1 : str\n",
    "    l2 : str\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRICTTranslator.constants import * \n",
    "from MRICTTranslator.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_file_path = CONFIG_FILE_PATH,\n",
    "                 params_file_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.training \n",
    "        create_directories([config.root_dir])\n",
    "        params = self.params \n",
    "        dataset = 'artifacts/data_ingestion/dataset/Dataset/images/'\n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_path=config.model_path,\n",
    "            dataset=str(dataset),\n",
    "            img_shape=params.IMAGE_SHAPE,\n",
    "            epochs=params.EPOCHS,\n",
    "            lr=params.LR,\n",
    "            l1=params.L1,\n",
    "            l2=params.L2,\n",
    "            \n",
    "            \n",
    "        )\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mritoct\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from MRICTTranslator.utils.common import preprocess_data,train\n",
    "from MRICTTranslator.models.cycle_gan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\tdef __init__(self, config: ModelTrainingConfig):\n",
    "\t\tself.config = config\n",
    "\t\t\n",
    "\t# load all images in a directory into memory\n",
    "\tdef load_images(self, path, size=(256,256)):\n",
    "\t\tdata_list = list()\n",
    "\t\t# enumerate filenames in directory, assume all are images\n",
    "\t\tfor filename in listdir(path):\n",
    "\t\t\t# load and resize the image\n",
    "\t\t\tpixels = load_img(path + filename, target_size=size)\n",
    "\t\t\t# convert to numpy array\n",
    "\t\t\tpixels = img_to_array(pixels)\n",
    "\t\t\t# store\n",
    "\t\t\tdata_list.append(pixels)\n",
    "\t\treturn asarray(data_list)\n",
    "\tdef model_train(self):\n",
    "\t\tdataA = self.load_images(self.config.dataset + 'trainA/')\n",
    "\t\tdataB = self.load_images(self.config.dataset + 'trainB/')\n",
    "\t\t# load image data\n",
    "\t\tdata = [dataA, dataB]\n",
    "\t\tdataset = preprocess_data(data)\n",
    "\t\t# define input shape based on the loaded dataset\n",
    "\n",
    "\t\timage_shape = dataset[0].shape[1:]\n",
    "\t\t# generator: A -> B\n",
    "\t\tg_model_AtoB = define_generator(image_shape)\n",
    "\t\t# generator: B -> A\n",
    "\t\tg_model_BtoA = define_generator(image_shape)\n",
    "\t\t# discriminator: A -> [real/fake]\n",
    "\t\td_model_A = define_discriminator(image_shape)\n",
    "\t\t# discriminator: B -> [real/fake]\n",
    "\t\td_model_B = define_discriminator(image_shape)\n",
    "\t\t# composite: A -> B -> [real/fake, A]\n",
    "\t\tc_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "\t\t# composite: B -> A -> [real/fake, B]\n",
    "\t\tc_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "\t\tstart1 = datetime.now()\n",
    "\t\t# train models\n",
    "\t\ttrain(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=self.config.epochs)\n",
    "\n",
    "\t\tstop1 = datetime.now()\n",
    "\t\t#Execution time of the model\n",
    "\t\texecution_time = stop1-start1\n",
    "\t\tprint(\"Execution time is: \", execution_time)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-06 11:23:29,334: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-06-06 11:23:29,338: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-06 11:23:29,340: INFO: common: created directory at: artifacts]\n",
      "[2024-06-06 11:23:29,343: INFO: common: created directory at: artifacts/training]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts/data_ingestion/dataset/images/trainA/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     model_train\u001b[38;5;241m.\u001b[39mmodel_train()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     model_training_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_training_config()\n\u001b[1;32m      4\u001b[0m     model_train \u001b[38;5;241m=\u001b[39m Training(config\u001b[38;5;241m=\u001b[39mmodel_training_config)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmodel_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36mTraining.model_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m \tdataA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainA/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \tdataB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_images(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainB/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \t\u001b[38;5;66;03m# load image data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m, in \u001b[0;36mTraining.load_images\u001b[0;34m(self, path, size)\u001b[0m\n\u001b[1;32m      7\u001b[0m data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# enumerate filenames in directory, assume all are images\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m \t\u001b[38;5;66;03m# load and resize the image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \tpixels \u001b[38;5;241m=\u001b[39m load_img(path \u001b[38;5;241m+\u001b[39m filename, target_size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m     12\u001b[0m \t\u001b[38;5;66;03m# convert to numpy array\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts/data_ingestion/dataset/images/trainA/'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_training_config()\n",
    "    model_train = Training(config=model_training_config)\n",
    "    model_train.model_train()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
