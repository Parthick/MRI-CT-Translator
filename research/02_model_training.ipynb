{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 10:27:49.537579: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/towet/Desktop/OpenProjects/MRI-CT-Translator/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 10:28:55.689054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/towet/Desktop/OpenProjects/MRI-CT-Translator'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "from pathlib import Path \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir : Path \n",
    "    model_path_AtoB : Path \n",
    "    model_path_BtoA : Path\n",
    "    dataset : Path \n",
    "    img_shape : tuple\n",
    "    epochs : int\n",
    "    lr : float\n",
    "    l1 : str\n",
    "    l2 : str\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRICTTranslator.constants import * \n",
    "from MRICTTranslator.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_file_path = CONFIG_FILE_PATH,\n",
    "                 params_file_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.training \n",
    "        create_directories([config.root_dir])\n",
    "        params = self.params \n",
    "        dataset = 'artifacts/data_ingestion/dataset/Dataset/images/'\n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_path_AtoB=config.model_path_AtoB,\n",
    "            model_path_BtoA=config.model_path_BtoA,\n",
    "            dataset=str(dataset),\n",
    "            img_shape=params.IMAGE_SHAPE,\n",
    "            epochs=params.EPOCHS,\n",
    "            lr=params.LR,\n",
    "            l1=params.L1,\n",
    "            l2=params.L2,\n",
    "            \n",
    "            \n",
    "        )\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mritoct\n",
    "\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from MRICTTranslator.utils.common import preprocess_data, load_images, generate_fake_samples, generate_real_samples, summarize_performance, save_models, update_image_pool\n",
    "from MRICTTranslator.models.cycle_gan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\tdef __init__(self, config: ModelTrainingConfig):\n",
    "\t\tself.config = config\n",
    "\t\t\n",
    "\tdef train(self,\n",
    "\t\td_model_A,\n",
    "\t\td_model_B,\n",
    "\t\tg_model_AtoB,\n",
    "\t\tg_model_BtoA,\n",
    "\t\tc_model_AtoB,\n",
    "\t\tc_model_BtoA,\n",
    "\t\tdataset,\n",
    "\t\tepochs=1,\n",
    "\t):\n",
    "\t\t# define properties of the training run\n",
    "\t\t(\n",
    "\t\t\tn_epochs,\n",
    "\t\t\tn_batch,\n",
    "\t\t) = (\n",
    "\t\t\tepochs,\n",
    "\t\t\t1,\n",
    "\t\t)  # batch size fixed to 1 as suggested in the paper\n",
    "\t\t# determine the output square shape of the discriminator\n",
    "\t\tn_patch = d_model_A.output_shape[1]\n",
    "\t\t# unpack dataset\n",
    "\t\ttrainA, trainB = dataset\n",
    "\t\t# prepare image pool for fake images\n",
    "\t\tpoolA, poolB = list(), list()\n",
    "\t\t# calculate the number of batches per training epoch\n",
    "\t\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\t\t# calculate the number of training iterations\n",
    "\t\tn_steps = bat_per_epo * n_epochs\n",
    "\n",
    "\t\t# manually enumerate epochs\n",
    "\t\tfor i in range(n_steps):\n",
    "\t\t\t# select a batch of real samples from each domain (A and B)\n",
    "\t\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "\t\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "\t\t\t# generate a batch of fake samples using both B to A and A to B generators.\n",
    "\t\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "\t\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "\t\t\t# update fake images in the pool. Remember that the paper suggstes a buffer of 50 images\n",
    "\t\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "\t\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "\n",
    "\t\t\t# update generator B->A via the composite model\n",
    "\t\t\tg_loss2, _, _, _, _ = c_model_BtoA.train_on_batch(\n",
    "\t\t\t\t[X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA]\n",
    "\t\t\t)\n",
    "\t\t\t# update discriminator for A -> [real/fake]\n",
    "\t\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "\t\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "\n",
    "\t\t\t# update generator A->B via the composite model\n",
    "\t\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch(\n",
    "\t\t\t\t[X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB]\n",
    "\t\t\t)\n",
    "\t\t\t# update discriminator for B -> [real/fake]\n",
    "\t\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "\t\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "\n",
    "\t\t\t# summarize performance\n",
    "\t\t\t# Since our batch size =1, the number of iterations would be same as the size of our dataset.\n",
    "\t\t\t# In one epoch you'd have iterations equal to the number of images.\n",
    "\t\t\t# If you have 100 images then 1 epoch would be 100 iterations\n",
    "\t\t\tprint(\n",
    "\t\t\t\t\"Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]\"\n",
    "\t\t\t\t% (i + 1, dA_loss1, dA_loss2, dB_loss1, dB_loss2, g_loss1, g_loss2)\n",
    "\t\t\t)\n",
    "\t\t\t# evaluate the model performance periodically\n",
    "\t\t\t# If batch size (total images)=100, performance will be summarized after every 75th iteration.\n",
    "\t\t\tif (i + 1) % (bat_per_epo * 1) == 0:\n",
    "\t\t\t\t# plot A->B translation\n",
    "\t\t\t\tsummarize_performance(i, g_model_AtoB, trainA, \"AtoB\")\n",
    "\t\t\t\t# plot B->A translation\n",
    "\t\t\t\tsummarize_performance(i, g_model_BtoA, trainB, \"BtoA\")\n",
    "\t\t\tif (i + 1) % (bat_per_epo * 5) == 0:\n",
    "\t\t\t\t# save the models\n",
    "\t\t\t\t# #If batch size (total images)=100, model will be saved after\n",
    "\t\t\t\t# every 75th iteration x 5 = 375 iterations.\n",
    "\t\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA, self.config.model_path_AtoB, self.config.model_path_BtoA)\n",
    "\n",
    "\t\n",
    "\tdef model_train(self):\n",
    "\t\t# dataA is the CT scans and dataB is the MRI scans\n",
    "\t\tdataA = load_images(self.config.dataset + 'trainA/')\n",
    "\t\tdataB = load_images(self.config.dataset + 'trainB/')\n",
    "\t\t# load image data\n",
    "\t\tdata = [dataA, dataB]\n",
    "\t\tdataset = preprocess_data(data)\n",
    "\t\t# define input shape based on the loaded dataset\n",
    "\n",
    "\t\timage_shape = dataset[0].shape[1:]\n",
    "\t\t# generator: A -> B\n",
    "\t\tg_model_AtoB = define_generator(image_shape)\n",
    "\t\t# generator: B -> A\n",
    "\t\tg_model_BtoA = define_generator(image_shape)\n",
    "\t\t# discriminator: A -> [real/fake]\n",
    "\t\td_model_A = define_discriminator(image_shape)\n",
    "\t\t# discriminator: B -> [real/fake]\n",
    "\t\td_model_B = define_discriminator(image_shape)\n",
    "\t\t# composite: A -> B -> [real/fake, A]\n",
    "\t\tc_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "\t\t# composite: B -> A -> [real/fake, B]\n",
    "\t\tc_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "\t\tstart1 = datetime.now()\n",
    "\t\t# train models\n",
    "\t\ttrain(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=self.config.epochs)\n",
    "\n",
    "\t\tstop1 = datetime.now()\n",
    "\t\t#Execution time of the model\n",
    "\t\texecution_time = stop1-start1\n",
    "\t\tprint(\"Execution time is: \", execution_time)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-19 10:50:26,619: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-06-19 10:50:26,650: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-19 10:50:26,651: INFO: common: created directory at: artifacts]\n",
      "[2024-06-19 10:50:26,652: INFO: common: created directory at: artifacts/training]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_training_config()\n",
    "    model_train = Training(config=model_training_config)\n",
    "    model_train.model_train()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
